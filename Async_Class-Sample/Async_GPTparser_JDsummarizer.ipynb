{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "api_key = \"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\"\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_parser(jd):\n",
    "    system='''You are an excellent skilled talent recruiter, your task is to provide a concise structured summary of the given job description in a  JSON format.\n",
    "        You will be provided with job description.\n",
    "        The system instruction is:\n",
    "        Step-1:\n",
    "        Analyse and parse the following information from the job description, do not just extract the data, rephrase it meaningfully;\n",
    "        return the meaningful parsed data in a sturctured JSON format with key and corresponding value format as follows-\n",
    "        'Role':string\n",
    "        'Relevant Experiences required': string,\n",
    "        'Experience Duration required': string,\n",
    "        'Skillset and Tools required' : string,\n",
    "        'Project description': string,\n",
    "        'Responsibilities required': string,\n",
    "        'Certifications required': string\n",
    "        'Education required': string\n",
    "        If value of a key is missing in the job description then value should be null.\n",
    "        If not a job description then all the key's value should be null.\n",
    "        Step-2:\n",
    "        Only return the parsed JSON format resume, nothing else.'''\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "            Only return the structured parsed json format of the job description.\n",
    "            Information about the job description is given inside text delimited by triple backticks.\n",
    "\n",
    "            job description :```{jd}```\n",
    "\n",
    "            \"\"\"\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\", \n",
    "        #model=\"gpt-4\"\n",
    "        messages=[{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": prompt}]\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "    # Parse the JSON response\n",
    "    try:\n",
    "        output_json = json.loads(completion)\n",
    "    except json.JSONDecodeError as e:\n",
    "        st.error(f\"Error parsing JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate the elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time Taken for Parsing : {elapsed_time} seconds\")\n",
    "    return output_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=f'''Job description\n",
    "Qualifications :\n",
    "6+ years experience working in a Data Science role\n",
    "Extensive experience developing and deploying ML models in real world environments\n",
    "Bachelor's degree in Computer Science, Mathematics, Statistics, or other analytical fields\n",
    "Exceptional familiarity with Python, Java, Spark or other open-source software with data science libraries\n",
    "Experience in advanced math and statistics\n",
    "Excellent familiarity with command line linux environment\n",
    "Able to understand various data structures and common methods in data transformation\n",
    "Experience deploying machine learning models and measuring their impact\n",
    "Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages drawbacks.\n",
    "Preferred Qualifications :\n",
    "Experience developing recommendation systems\n",
    "Experience developing and deploying deep learning models\n",
    "Bachelor's or Master's Degree or PhD that included coursework in statistics, machine learning or data analysis\n",
    "Four+ years experience working with Hadoop, a NoSQL Database or other big data infrastructure\n",
    "Experience with being actively engaged in data science or other research-oriented position\n",
    "You would be comfortable collaborating with cross-functional teams.\n",
    "Active personal GitHub account.\n",
    "Role: Machine Learning Engineer\n",
    "Industry Type: IT Services & Consulting\n",
    "Department: Data Science & Analytics\n",
    "Employment Type: Full Time, Permanent\n",
    "Role Category: Data Science & Machine Learning\n",
    "Education\n",
    "UG: B.Sc in Maths, Computers, Statistics, BCA in Computers, B.A in Statistics, Maths, B.Tech/B.E. in Computers\n",
    "PG: MS/M.Sc(Science) in Statistics, M.A in Statistics\n",
    "Doctorate: Ph.D/Doctorate in Statistics\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken for Parsing : 4.355968952178955 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Role': 'Machine Learning Engineer',\n",
       " 'Relevant Experiences required': '6+ years experience working in a Data Science role',\n",
       " 'Experience Duration required': 'Extensive experience developing and deploying ML models in real world environments',\n",
       " 'Skillset and Tools required': 'Exceptional familiarity with Python, Java, Spark or other open-source software with data science libraries; Experience in advanced math and statistics; Excellent familiarity with command line linux environment; Able to understand various data structures and common methods in data transformation; Experience deploying machine learning models and measuring their impact; Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages drawbacks',\n",
       " 'Project description': None,\n",
       " 'Responsibilities required': None,\n",
       " 'Certifications required': None,\n",
       " 'Education required': \"Bachelor's degree in Computer Science, Mathematics, Statistics, or other analytical fields; Bachelor's or Master's Degree or PhD that included coursework in statistics, machine learning or data analysis; UG: B.Sc in Maths, Computers, Statistics, BCA in Computers, B.A in Statistics, Maths, B.Tech/B.E. in Computers; PG: MS/M.Sc(Science) in Statistics, M.A in Statistics; Doctorate: Ph.D/Doctorate in Statistics\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_parser(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system1='''You are an excellent skilled talent recruiter, your task is to provide a concise structured summary of the given job description in a  JSON format.\n",
    "        You will be provided with job description.\n",
    "        The system instruction is:\n",
    "        Step-1:\n",
    "        Analyse and parse the following information from the job description, do not just extract the data, rephrase it meaningfully;\n",
    "        return the meaningful parsed data in a sturctured JSON format with key and corresponding value format as follows-\n",
    "        'Role':string\n",
    "        'Relevant Experiences required': string,\n",
    "        'Experience Duration required': string,\n",
    "        'Skillset and Tools required' : string,\n",
    "        If value of a key is missing in the job description then value should be null.\n",
    "        If not a job description then all the key's value should be null.\n",
    "        Step-2:\n",
    "        Only return the parsed JSON format resume, nothing else.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system2='''You are an excellent skilled talent recruiter, your task is to provide a concise structured summary of the given job description in a  JSON format.\n",
    "        You will be provided with job description.\n",
    "        The system instruction is:\n",
    "        Step-1:\n",
    "        Analyse and parse the following information from the job description, do not just extract the data, rephrase it meaningfully;\n",
    "        return the meaningful parsed data in a sturctured JSON format with key and corresponding value format as follows-\n",
    "        'Role':string\n",
    "        'Relevant Experiences required': string,\n",
    "        'Experience Duration required': string,\n",
    "        'Skillset and Tools required' : string,\n",
    "        If value of a key is missing in the job description then value should be null.\n",
    "        If not a job description then all the key's value should be null.\n",
    "        Step-2:\n",
    "        Only return the parsed JSON format resume, nothing else.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting httpx\n",
      "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
      "     ---------------------------------------- 75.7/75.7 kB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi in c:\\users\\sudhe\\anaconda3\\lib\\site-packages (from httpx) (2020.6.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sudhe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sudhe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sudhe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sudhe\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting httpcore<0.19.0,>=0.18.0 (from httpx)\n",
      "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
      "     ---------------------------------------- 76.0/76.0 kB 4.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna in c:\\users\\sudhe\\anaconda3\\lib\\site-packages (from httpx) (2.10)\n",
      "Collecting sniffio (from httpx)\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting anyio<5.0,>=3.0 (from httpcore<0.19.0,>=0.18.0->httpx)\n",
      "  Downloading anyio-4.0.0-py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.1/83.1 kB ? eta 0:00:00\n",
      "Collecting h11<0.15,>=0.13 (from httpcore<0.19.0,>=0.18.0->httpx)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx)\n",
      "  Downloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: sniffio, h11, exceptiongroup, anyio, httpcore, httpx\n",
      "Successfully installed anyio-4.0.0 exceptiongroup-1.1.3 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 sniffio-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in c:\\users\\sudhe\\anaconda3\\lib\\site-packages (1.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sudhe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sudhe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sudhe\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sudhe\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Role': 'Machine Learning Engineer', 'Relevant Experiences required': '6+ years experience working in a Data Science role', 'Experience Duration required': 'Extensive experience developing and deploying ML models in real world environments', 'Skillset and Tools required': 'Exceptional familiarity with Python, Java, Spark or other open-source software with data science libraries, Experience in advanced math and statistics, Excellent familiarity with command line linux environment, Able to understand various data structures and common methods in data transformation, Experience deploying machine learning models and measuring their impact, Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages drawbacks.'}\n",
      "Execution time: 3.44 seconds\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Get OpenAI API key from environment variable\n",
    "API_KEY = \"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\"\n",
    "\n",
    "jd = text\n",
    "systems = [system1, system2]\n",
    "\n",
    "\n",
    "async def async_openai_request(session, jd, system):\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    prompt = f\"\"\"\n",
    "            Only return the structured parsed json format of the job description.\n",
    "            Information about the job description is given inside text delimited by triple backticks.\n",
    "\n",
    "            job description :```{jd}```\n",
    "\n",
    "            \"\"\"\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo-16k\",\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    async with session.post(url, json=data, headers=headers) as response:\n",
    "        return await response.json()\n",
    "\n",
    "async def fetch_responses():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        results = await asyncio.gather(*(async_openai_request(session, jd, system) for system in systems))\n",
    "    return results\n",
    "\n",
    "def process_responses(responses):\n",
    "    output_list = [json.loads(resp['choices'][0]['message']['content']) for resp in responses]   \n",
    "    # Merging dictionaries\n",
    "    combined_dict = {k: v for response in output_list for k, v in response.items()}\n",
    "    return combined_dict\n",
    "\n",
    "async def main():\n",
    "    responses = await fetch_responses()\n",
    "    return process_responses(responses)\n",
    "\n",
    "# Benchmarking\n",
    "start_time = time.time()\n",
    "print(await main())\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Role': 'Machine Learning Engineer', 'Relevant Experiences required': '6+ years experience working in a Data Science role', 'Experience Duration required': 'Extensive experience developing and deploying ML models in real world environments', 'Skillset and Tools required': 'Exceptional familiarity with Python, Java, Spark or other open-source software with data science libraries, Experience in advanced math and statistics, Excellent familiarity with command line linux environment, Able to understand various data structures and common methods in data transformation, Experience deploying machine learning models and measuring their impact, Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages drawbacks.', 'Preferred Qualifications': \"Experience developing recommendation systems, Experience developing and deploying deep learning models, Bachelor's or Master's Degree or PhD that included coursework in statistics, machine learning or data analysis, Four+ years experience working with Hadoop, a NoSQL Database or other big data infrastructure, Experience with being actively engaged in data science or other research-oriented position, You would be comfortable collaborating with cross-functional teams, Active personal GitHub account.\"}\n",
      "Execution time: 7.35 seconds\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "class JobDescriptionProcessor:\n",
    "    \n",
    "    API_KEY = \"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\"\n",
    "    \n",
    "    def __init__(self, job_description):\n",
    "        self.job_description = job_description\n",
    "        self.systems = [\n",
    "        '''You are an excellent skilled talent recruiter, your task is to provide a concise structured summary of the given job description in a  JSON format.\n",
    "        You will be provided with job description.\n",
    "        The system instruction is:\n",
    "        Step-1:\n",
    "        Analyse and parse the following information from the job description, do not just extract the data, rephrase it meaningfully;\n",
    "        return the meaningful parsed data in a sturctured JSON format with key and corresponding value format as follows-\n",
    "        'Role':string\n",
    "        'Relevant Experiences required': string,\n",
    "        'Experience Duration required': string,\n",
    "        'Skillset and Tools required' : string,\n",
    "        If value of a key is missing in the job description then value should be null.\n",
    "        If not a job description then all the key's value should be null.\n",
    "        Step-2:\n",
    "        Only return the parsed JSON format resume, nothing else''', #(system1)\n",
    "        '''You are an excellent skilled talent recruiter, your task is to provide a concise structured summary of the given job description in a  JSON format.\n",
    "        You will be provided with job description.\n",
    "        The system instruction is:\n",
    "        Step-1:\n",
    "        Analyse and parse the following information from the job description, do not just extract the data, rephrase it meaningfully;\n",
    "        return the meaningful parsed data in a sturctured JSON format with key and corresponding value format as follows-\n",
    "        'Role':string\n",
    "        'Relevant Experiences required': string,\n",
    "        'Experience Duration required': string,\n",
    "        'Skillset and Tools required' : string,\n",
    "        If value of a key is missing in the job description then value should be null.\n",
    "        If not a job description then all the key's value should be null.\n",
    "        Step-2:\n",
    "        Only return the parsed JSON format resume, nothing else.''' ] # (system2 )\n",
    "        \n",
    "\n",
    "    async def async_openai_request(self, session, system):\n",
    "        url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        prompt = f\"\"\"\n",
    "                Only return the structured parsed json format of the job description.\n",
    "                Information about the job description is given inside text delimited by triple backticks.\n",
    "                job description :```{self.job_description}```\n",
    "                \"\"\"\n",
    "        data = {\n",
    "            \"model\": \"gpt-3.5-turbo-16k\",\n",
    "            \"messages\": [{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": prompt}],\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "        async with session.post(url, json=data, headers=headers) as response:\n",
    "            return await response.json()\n",
    "\n",
    "    async def fetch_responses(self):\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            results = await asyncio.gather(*(self.async_openai_request(session, system) for system in self.systems))\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def process_responses(responses):\n",
    "        output_list = [json.loads(resp['choices'][0]['message']['content']) for resp in responses]   \n",
    "        combined_dict = {k: v for response in output_list for k, v in response.items()}\n",
    "        return combined_dict\n",
    "\n",
    "    async def process(self):\n",
    "        responses = await self.fetch_responses()\n",
    "        return self.process_responses(responses)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # For testing purposes\n",
    "    jd_text = f'''Job description\n",
    "Qualifications :\n",
    "6+ years experience working in a Data Science role\n",
    "Extensive experience developing and deploying ML models in real world environments\n",
    "Bachelor's degree in Computer Science, Mathematics, Statistics, or other analytical fields\n",
    "Exceptional familiarity with Python, Java, Spark or other open-source software with data science libraries\n",
    "Experience in advanced math and statistics\n",
    "Excellent familiarity with command line linux environment\n",
    "Able to understand various data structures and common methods in data transformation\n",
    "Experience deploying machine learning models and measuring their impact\n",
    "Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages drawbacks.\n",
    "Preferred Qualifications :\n",
    "Experience developing recommendation systems\n",
    "Experience developing and deploying deep learning models\n",
    "Bachelor's or Master's Degree or PhD that included coursework in statistics, machine learning or data analysis\n",
    "Four+ years experience working with Hadoop, a NoSQL Database or other big data infrastructure\n",
    "Experience with being actively engaged in data science or other research-oriented position\n",
    "You would be comfortable collaborating with cross-functional teams.\n",
    "Active personal GitHub account.\n",
    "Role: Machine Learning Engineer\n",
    "Industry Type: IT Services & Consulting\n",
    "Department: Data Science & Analytics\n",
    "Employment Type: Full Time, Permanent\n",
    "Role Category: Data Science & Machine Learning\n",
    "Education\n",
    "UG: B.Sc in Maths, Computers, Statistics, BCA in Computers, B.A in Statistics, Maths, B.Tech/B.E. in Computers\n",
    "PG: MS/M.Sc(Science) in Statistics, M.A in Statistics\n",
    "Doctorate: Ph.D/Doctorate in Statistics\n",
    "'''\n",
    "\n",
    "    processor = JobDescriptionProcessor(jd_text)\n",
    "\n",
    "    start_time = time.time()\n",
    "    #result = asyncio.run(processor.process())\n",
    "    result = await processor.process()\n",
    "\n",
    "    print(result)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\"Execution time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
